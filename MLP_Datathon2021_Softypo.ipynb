{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import kfold_model as kfm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# felix function\n",
    "def outlier_detector_IQR(df,features,n_IQR, all_data = True):  \n",
    "\n",
    "  dmin = {}\n",
    "  dmax = {}\n",
    "  lower_b = {}\n",
    "  higher_b = {}\n",
    "  count_min = {}\n",
    "  count_max = {}\n",
    "\n",
    "  for i in features:\n",
    "    Q1 = df[i].quantile(0.25)\n",
    "    Q3 = df[i].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit, higher_limit = Q1 - n_IQR*IQR, Q3 +n_IQR*IQR\n",
    "\n",
    "    lower_b[i] = [np.round(lower_limit,2)]   # min value per Log\n",
    "    higher_b[i] = [np.round(higher_limit,2)] # max value per Log\n",
    "\n",
    "    if df[i].min() < lower_limit:      \n",
    "      dmin[i] = [np.round(df[i].min(),2)]\n",
    "      count_min[i] = [len(df[i].loc[df[i] < lower_limit])]\n",
    "    else:\n",
    "      dmin[i] = '-----'\n",
    "      count_min[i] = '-----'\n",
    "    if df[i].max() > higher_limit:\n",
    "      dmax[i] = [np.round(df[i].max(),2)]\n",
    "      count_max[i] = [len(df[i].loc[df[i] > higher_limit])]\n",
    "    else:\n",
    "      dmax[i] = '-----'\n",
    "      count_max[i] = '-----'\n",
    "\n",
    "  lower = pd.DataFrame(lower_b).T.rename(columns={0:'Lower_Limit'})\n",
    "  min = pd.DataFrame(dmin).T.rename(columns={0:'1st_Min_Outlier'})\n",
    "  min_count = pd.DataFrame(count_min).T.rename(columns={0:'Total_Min_Out'})\n",
    "  higher = pd.DataFrame(higher_b).T.rename(columns={0:'Higher_Limit'})  \n",
    "  max = pd.DataFrame(dmax).T.rename(columns={0:'Last_Max_Outlier'})\n",
    "  max_count = pd.DataFrame(count_max).T.rename(columns={0:'Total_Max_Out'})  \n",
    "\n",
    "  return pd.concat([lower,min,min_count,higher,max,max_count],axis=1) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# felix function\n",
    "def outlier_replacer(df,column,min=None,max=None):  \n",
    "\n",
    "  if min != None:\n",
    "    min_idx = list(df.loc[df[column]<=min].index.values)\n",
    "    df.at[min_idx,column] = min\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "  if max != None:\n",
    "    max_idx = list(df.loc[df[column]>=max].index.values)\n",
    "    df.at[max_idx,column] = max\n",
    "  else:\n",
    "    pass  \n",
    "\n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preparing data for the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# loding eda dataset\n",
    "well_data_Softypo_ft = pd.read_csv('final_well_data_Softypo_ft.csv', index_col=0)\n",
    "#well_data_Softypo_ft.describe()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# looking for outliers\n",
    "#outlier_detector_IQR(well_data_Softypo_ft[well_data_Softypo_ft.dtypes[well_data_Softypo_ft.dtypes != 'object'].index],well_data_Softypo_ft[well_data_Softypo_ft.dtypes[well_data_Softypo_ft.dtypes != 'object'].index].keys(),1.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# droping outlier values\n",
    "outlier_replacer(well_data_Softypo_ft,'Gas Maximum (mcf)',min=0,max=19436.24)\n",
    "outlier_replacer(well_data_Softypo_ft,'Oil Total Cum (bbl)',min=0,max=14803.74)\n",
    "outlier_replacer(well_data_Softypo_ft,'Initial Hydrostatic Pressure (kPa)',min=0,max=39112.16)\n",
    "outlier_replacer(well_data_Softypo_ft,'Water Maximum (bbl)',min=0,max=1565.31) \n",
    "outlier_replacer(well_data_Softypo_ft,'Gas Total Cum (mcf)',min=0,max=227782.69) \n",
    "outlier_replacer(well_data_Softypo_ft,'Final Hydrostatic Pressure (kPa)',min=0,max=38256.44)  \n",
    "outlier_replacer(well_data_Softypo_ft,'Oil Maximum (bbl)',min=0,max=3295.82) \n",
    "outlier_replacer(well_data_Softypo_ft,'GOR Total Average',min=0,max=5663.28)\n",
    "outlier_replacer(well_data_Softypo_ft,'Water Total Cum (bbl)',min=0,max=66035.43) \n",
    "outlier_replacer(well_data_Softypo_ft,'TD_ft',min=None,max=15830.82)\n",
    "outlier_replacer(well_data_Softypo_ft,'Total Vertical Depth (ft)',min=None,max=15231.25) \n",
    "outlier_replacer(well_data_Softypo_ft,'VSHALE',min=0,max=0.95) \n",
    "outlier_replacer(well_data_Softypo_ft,'PHIT',min=0,max=None) \n",
    "outlier_replacer(well_data_Softypo_ft,'ILD',min=0,max=2.97) \n",
    "outlier_replacer(well_data_Softypo_ft,'DT',min=20.28,max=112.42)\n",
    "outlier_replacer(well_data_Softypo_ft,'GR',min=0,max=143.62) \n",
    "outlier_replacer(well_data_Softypo_ft,'U',min=None,max=16.16) \n",
    "print ('done')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#well_data_Softypo_ft.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# % of nan\n",
    "#well_data_Softypo_ft.isnull().mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#droping columns with nan higer than 50%\n",
    "well_data_Softypo_ft = well_data_Softypo_ft.loc[:, well_data_Softypo_ft.isnull().mean() < .5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "well_data_Softypo_ft.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# selecting working variables for TVD estimation from WellHeader_Datathon.csv\n",
    "df = pd.DataFrame(well_data_Softypo_ft.loc[:,['source', 'BHT', 'Field', 'TrueTemp', 'BHT_md_ft', 'BHT_ss_ft', 'SurfaceLatitude_NAD83', 'SurfaceLongitude_NAD83', 'VSHALE', 'PHIT', 'SW']], index=well_data_Softypo_ft.index)\n",
    "\n",
    "# casting categorilac data\n",
    "df[df.dtypes[df.dtypes == 'object'].index] = df[df.dtypes[df.dtypes == 'object'].index].astype('category')"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_num = df[df.dtypes[df.dtypes != 'category'].index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# one hot encoder for categories\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "df_ohe = pd.DataFrame(ohe.fit_transform(df[df.dtypes[df.dtypes == 'category'].index]), columns=ohe.get_feature_names(df.dtypes[df.dtypes == 'category'].index), index=df.index)\n",
    "# adding numerical columns\n",
    "df_ohe = pd.concat([df[df.dtypes[df.dtypes != 'category'].index], df_ohe], axis=1, verify_integrity=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generating train and target dataframes\n",
    "df_train = df_ohe[~df_ohe.TrueTemp.isna()]\n",
    "# target datasets\n",
    "df_target = df_ohe[df_ohe.TrueTemp.isna()]"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# spliting the training and validation data\r\n",
    "train_x, holdout_x, train_y, holdout_y = train_test_split(df_train.loc[:, df_train.columns != 'TrueTemp'], df_train.TrueTemp, test_size=0.1, random_state=42)\r\n",
    "\r\n",
    "# filling nan values\r\n",
    "train_x = train_x.fillna(0)\r\n",
    "holdout_x = holdout_x.fillna(0)\r\n",
    "\r\n",
    "# features scaling\r\n",
    "sc = StandardScaler()\r\n",
    "train_x = sc.fit_transform(train_x)\r\n",
    "holdout_x = sc.transform(holdout_x)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# saving train and validation sets in binary format\r\n",
    "np.save('train_x.npy', train_x)\r\n",
    "np.save('holdout_x.npy', holdout_x)\r\n",
    "np.save('train_y.npy', train_y)\r\n",
    "np.save('holdout_y.npy', holdout_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## reset kernel to clean memory for training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import kfold_model as kfm\r\n",
    "import keras_tuner_two_steps as kfts\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "#from keras_tuner_f import HyperModel_F\r\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\r\n",
    "from sklearn.metrics import mean_absolute_error\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# loading train and validation sets in binary format\r\n",
    "train_x = np.load('train_x.npy')\r\n",
    "holdout_x = np.load('holdout_x.npy')\r\n",
    "train_y = np.load('train_y.npy')\r\n",
    "holdout_y = np.load('holdout_y.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print ('train_x: ',train_x.shape)\r\n",
    "print ('holdout_x: ',holdout_x.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_x:  (553, 12)\n",
      "holdout_x:  (62, 12)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "first_tuner, second_tuner, best_model = kfts.two_steps(train_x, train_y, holdout_x, holdout_y, project_name='GTX_dataset', path=None, oracle_1st='random', oracle_2nd='bayesian', epochs_1st=15, epochs_2nd=5, seed=42, activation_hidden='relu', activation_output='linear', loss_function='mean_squared_error', metrics=['mean_absolute_error'], layers=[2,23], units=[32,1024,32], initializers=['glorot_uniform'], l1_reg=[0.0], l2_reg=[0.0], dropout=[0.0,0.0,0.5], optimizers=['Adam'], learning_rates=[0.001])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial 3 Complete [00h 00m 01s]\n",
      "mean_absolute_error: 78.21784210205078\n",
      "\n",
      "Best mean_absolute_error So Far: 67.7645034790039\n",
      "Total elapsed time: 00h 00m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in .kerastunner\\GTX_dataset\n",
      "Showing 1 best trials\n",
      "Objective(name='mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 32\n",
      "kernel_initializer_0: glorot_uniform\n",
      "l1_0: 0.0\n",
      "l2_0: 0.0\n",
      "dropout_0: 0.0\n",
      "units_1: 32\n",
      "kernel_initializer_1: glorot_uniform\n",
      "l1_1: 0.0\n",
      "l2_1: 0.0\n",
      "dropout_1: 0.0\n",
      "optimizer: Adam\n",
      "learning_rate: 0.001\n",
      "units_2: 32\n",
      "kernel_initializer_2: glorot_uniform\n",
      "l1_2: 0.0\n",
      "l2_2: 0.0\n",
      "dropout_2: 0.0\n",
      "Score: 67.7645034790039\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## implementing k-folds model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models, histories, holdout_score = kfm.model_kfolds(train_x, train_y, holdout=[holdout_x,holdout_y], model='v1', num_folds=5, batch_size=None, steps_per_epoch=100, activation='relu', loss_function='mean_squared_error', metrics=['mean_absolute_error'], optimizer='adam', max_epochs=1000, verbosity=3, workers=6, use_multiprocessing=True, continue_training=False, save_models_afte_training=True, reshuffle=False, random_state=42, path=None, plot_results=True, plot_width=1500, plot_height=500)"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kfm.graph_training_plotly(histories, holdout_scores=None, width=1600, height=500, template='plotly_dark')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "histories = kfm.histories_loader_kfolds(path='_Kfolds_models')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models = kfm.model_loader_kfolds(path='_Kfolds_models', ext=False, num_folds=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yhat, yhat_score, predictions, scores = kfm.predict_kfolds(holdout_x, holdout_y, models, todrop=None, output=None, plot_results=True, plot_width=1500, plot_height=500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kfm.graph_results_plotly(holdout_y, predictions, scores=scores, width=1500, height=500, template='plotly_dark', renderer='notebook')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preparing submission dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creating submission dataframe\r\n",
    "\"\"\"\"df_target = df_target.fillna(0)\r\n",
    "df_target['TrueTemp'] = models['k4_model'].predict(sc.transform(df_target.loc[:, df_target.columns != 'TrueTemp']))\r\n",
    "df_to_send = df_target.reset_index()\r\n",
    "df_to_send[['UWI', 'TrueTemp']].to_csv('predictions.csv', index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creating submission dataframe\r\n",
    "\"\"\"\"df_target = df_target.fillna(0)\r\n",
    "\r\n",
    "df_target['k1'] = models['k1_model'].predict(sc.transform(df_target.loc[:, df_target.columns != 'TrueTemp']))\r\n",
    "df_target['k2'] = models['k2_model'].predict(sc.transform(df_target.loc[:, df_target.columns != 'TrueTemp']))\r\n",
    "df_target['k3'] = models['k3_model'].predict(sc.transform(df_target.loc[:, df_target.columns != 'TrueTemp']))\r\n",
    "df_target['k4'] = models['k4_model'].predict(sc.transform(df_target.loc[:, df_target.columns != 'TrueTemp']))\r\n",
    "df_target['k5'] = models['k5_model'].predict(sc.transform(df_target.loc[:, df_target.columns != 'TrueTemp']))\r\n",
    "df_target['TrueTemp'] = (df_target['k1']+df_target['k2']+df_target['k3']+df_target['k3']+df_target['k5'])/5\r\n",
    "df_to_send = df_target.reset_index()\r\n",
    "df_to_send[['UWI', 'TrueTemp']].to_csv('predictions.csv', index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ziping submission\r\n",
    "import zipfile\r\n",
    "zipfile.ZipFile('predictions.zip', mode='w').write(\"predictions.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mapping results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_plot = pd.DataFrame(df_ohe)\r\n",
    "df_plot = df_plot.fillna(0)\r\n",
    "df_plot['Prediction'] = yhat\r\n",
    "df_plot['TrueTemp'] = df_ohe['TrueTemp']\r\n",
    "df_plot['TrueTemp'] = df_plot['TrueTemp'].fillna(df_plot['Prediction'])\r\n",
    "df_plot['thermal_grad'] = ((df_plot['TrueTemp']-15.5)+273.15)/((df_plot['BHT_md_ft'])/3.28) # K/m"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = pd.DataFrame(well_data_Softypo_ft)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test['thermal_cond'] = 1.15 + 2.59*(test['RHO']*1000) + 1.08*test['PHIT'] - 0.28*(test['RHO']*1000*5) - 0.0083*((test['BHT']-15.5)+273.15) - 1.66*test['VSHALE']\n",
    "test['thermal_diff'] = 1.59 + 0.57*(test['RHO']*1000) - 0.70*test['PHIT'] - 0.113*(test['RHO']*1000*5) - 0.0043*((test['BHT']-15.5)+273.15) - 0.45*test['VSHALE']\n",
    "# test['heat_capacity'] = 584 - 194.4*(test['RHO']*1000) + 1250*test['PHIT'] + 10.93*test['U'] + 4.03*((test['BHT']-15.5)+273.15) - 435.9*test['VSHALE']\n",
    "test['spec_heat'] = test['thermal_cond']/((test['RHO']*1000)*test['thermal_diff'])\n",
    "#test['heat_flux'] = test['thermal_cond']*(test['thermal_grad']) # W/M2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_plot = df_plot.loc[:,['TrueTemp', 'thermal_grad']]\n",
    "df_plot['SurfaceLatitude_NAD83'] = df['SurfaceLatitude_NAD83']\n",
    "df_plot['SurfaceLongitude_NAD83'] = df['SurfaceLongitude_NAD83']\n",
    "df_plot['Field'] = df['Field']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_plot['thermal_cond'] = well_data_Softypo_ft['thermal_cond']\n",
    "df_plot['thermal_diff'] = well_data_Softypo_ft['thermal_diff']\n",
    "df_plot['spec_heat'] = well_data_Softypo_ft['spec_heat']\n",
    "\n",
    "df_plot['heat_flux'] = df_plot['thermal_cond']*(df_plot['thermal_grad']) # W/M2\n",
    "df_plot['heat_flux'] = df_plot['heat_flux'].fillna(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "token = \"pk.eyJ1Ijoic29mdHlwbyIsImEiOiJja3B5bDFxdTQwZWdvMnZxc3BicGg0bDh5In0.yySzE4jZALgo-JAHdS0zrA\" # you will need your own token\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_mapbox(df_plot.loc[df_plot['Field'] == 'Eaglebine'], lat=\"SurfaceLatitude_NAD83\", lon=\"SurfaceLongitude_NAD83\", color=\"TrueTemp\", size=\"heat_flux\",\n",
    "                  color_continuous_scale=px.colors.sequential.solar, size_max=30, zoom=5, width=1000, height=500)\n",
    "fig.update_layout(mapbox_style=\"light\", mapbox_accesstoken=token)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = px.scatter_mapbox(df_plot.loc[df_plot['Field'] == 'Duvernay'], lat=\"SurfaceLatitude_NAD83\", lon=\"SurfaceLongitude_NAD83\", color=\"TrueTemp\", size=\"heat_flux\",\n",
    "                  color_continuous_scale=px.colors.sequential.solar, size_max=30, zoom=5, width=1000, height=500)\n",
    "fig.update_layout(mapbox_style=\"light\", mapbox_accesstoken=token)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from inspect import getmembers, isfunction\r\n",
    "\r\n",
    "from tensorflow.keras import activations\r\n",
    "print(getmembers(activations, isfunction))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a39ce970cf8d6d7649087dcd2c302fff6fdd838fe61e073644cc83126ce75f11"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}